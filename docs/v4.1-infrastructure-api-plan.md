# Claude-Slack v4.1: Infrastructure API Implementation Plan

## Executive Summary

Claude-Slack needs to expose a programmatic Python API that allows the intelligence layer (claude-brain) to access infrastructure capabilities beyond what MCP tools provide. This document outlines the implementation required to fulfill claude-slack's role as the **unopinionated infrastructure layer** for the knowledge system.

## Design Principles

1. **Clean Public API**: Expose functionality through a well-defined Python package, not internal classes
2. **Backward Compatible**: All existing MCP tools continue to work unchanged
3. **No Intelligence**: No pattern extraction, synthesis, or curation - pure data operations
4. **Extensible**: Allow custom functions (like rankers) to be injected without modification
5. **Efficient**: Support the performance needs of the intelligence layer

## Required Implementation

### 1. Package Structure

Create a new Python package structure for the public API:

```
claude-slack/
├── claude_slack/                 # NEW: Public Python package
│   ├── __init__.py              # Package exports
│   ├── api.py                   # Main API class
│   ├── models.py                # Data models (Message, SearchResult, etc.)
│   ├── filters.py               # Metadata filter parsing
│   └── exceptions.py            # Custom exceptions
├── mcp/                         # Existing MCP server (unchanged)
│   ├── server.py
│   └── [existing structure]
└── setup.py                     # NEW: Package installation
```

### 2. Core API Class

```python
# claude_slack/api.py

from typing import Dict, List, Optional, Callable, Any
from dataclasses import dataclass
from datetime import datetime
from .models import Message, SearchResult, AggregationResult
from .filters import MetadataFilter

class ClaudeSlackAPI:
    """
    Public API for claude-slack infrastructure.
    
    This is the primary interface for external systems (like claude-brain)
    to interact with the claude-slack knowledge store.
    """
    
    def __init__(self, 
                 db_path: str,
                 enable_semantic: bool = True,
                 cache_embeddings: bool = True):
        """
        Initialize the API connection.
        
        Args:
            db_path: Path to SQLite database
            enable_semantic: Use ChromaDB for semantic search if available
            cache_embeddings: Cache embeddings for performance
        """
        self._db_path = db_path
        self._init_storage()
    
    # ========== Core Operations (Existing) ==========
    
    async def store_message(self, 
                           channel_id: str,
                           sender_id: str, 
                           content: str,
                           metadata: Optional[Dict] = None,
                           confidence: Optional[float] = None,
                           timestamp: Optional[datetime] = None) -> int:
        """Store a message with metadata."""
        pass
    
    async def search(self,
                    query: Optional[str] = None,
                    ranking_profile: str = "balanced",
                    limit: int = 20,
                    **filters) -> List[SearchResult]:
        """Basic semantic/keyword search."""
        pass
    
    async def get_message(self, message_id: int) -> Optional[Message]:
        """Retrieve a single message by ID."""
        pass
    
    # ========== NEW: Metadata Query Capabilities ==========
    
    async def query_by_metadata(self,
                               filters: Dict[str, Any],
                               query: Optional[str] = None,
                               limit: int = 100,
                               order_by: Optional[str] = None) -> List[Message]:
        """
        Query messages by metadata fields using MongoDB-like syntax.
        
        Args:
            filters: Metadata filters using MongoDB-like operators
            query: Optional semantic search query to combine
            limit: Maximum results
            order_by: Sort field (e.g., "confidence DESC")
        
        Example:
            filters = {
                "breadcrumbs.files": {"$contains": "auth.py"},
                "breadcrumbs.decisions": {"$in": ["use-jwt", "stateless"]},
                "confidence": {"$gte": 0.8},
                "timestamp": {"$gte": "2024-01-01"}
            }
        
        Supported operators:
            $eq, $ne, $gt, $gte, $lt, $lte     - Comparisons
            $in, $nin                           - List membership
            $contains, $not_contains            - String/list contains
            $exists                             - Field existence
            $regex                              - Pattern matching
            $and, $or                           - Logical operators
        """
        pass
    
    # ========== NEW: Custom Ranking Support ==========
    
    async def search_with_custom_ranker(self,
                                       query: str,
                                       ranker: Callable[[Message, Dict], float],
                                       limit: int = 20,
                                       pre_filter: Optional[Dict] = None,
                                       candidate_multiplier: int = 3) -> List[SearchResult]:
        """
        Search with custom ranking function.
        
        Args:
            query: Semantic search query
            ranker: Function (message, scores) -> float
                   where scores = {
                       "similarity": 0.0-1.0,
                       "confidence": 0.0-1.0, 
                       "age_hours": float,
                       "decay": 0.0-1.0
                   }
            limit: Final result count
            pre_filter: Optional metadata filters
            candidate_multiplier: Fetch N*limit candidates for re-ranking
        
        Example:
            def my_ranker(message: Message, scores: Dict) -> float:
                # Custom logic using message.metadata
                if "security" in message.metadata.get("tags", []):
                    return scores["similarity"] * 1.5
                return scores["similarity"]
            
            results = await api.search_with_custom_ranker(
                query="authentication",
                ranker=my_ranker
            )
        """
        pass
    
    # ========== NEW: Aggregation Capabilities ==========
    
    async def aggregate_by_metadata(self,
                                   group_by: str,
                                   metrics: List[str],
                                   filters: Optional[Dict] = None,
                                   time_window: Optional[str] = None) -> List[AggregationResult]:
        """
        Aggregate messages by metadata fields.
        
        Args:
            group_by: Metadata field to group by (supports nested)
            metrics: List of metrics to calculate
                    ["count", "avg_confidence", "max_confidence", 
                     "min_confidence", "unique_senders"]
            filters: Optional metadata filters
            time_window: Optional time window ("7d", "24h", "1M")
        
        Example:
            results = await api.aggregate_by_metadata(
                group_by="metadata.breadcrumbs.patterns",
                metrics=["count", "avg_confidence"],
                filters={"confidence": {"$gte": 0.7}},
                time_window="7d"
            )
            # Returns: [
            #   {"pattern": "middleware", "count": 15, "avg_confidence": 0.85},
            #   {"pattern": "decorator", "count": 8, "avg_confidence": 0.92}
            # ]
        """
        pass
    
    # ========== NEW: Breadcrumb-Specific Queries ==========
    
    async def find_by_breadcrumbs(self,
                                 files: Optional[List[str]] = None,
                                 commits: Optional[List[str]] = None,
                                 decisions: Optional[List[str]] = None,
                                 patterns: Optional[List[str]] = None,
                                 mode: str = "any") -> List[Message]:
        """
        Specialized query for breadcrumb fields.
        
        Args:
            files: File paths to match
            commits: Commit hashes to match
            decisions: Decision tags to match  
            patterns: Pattern names to match
            mode: "any" (OR) or "all" (AND)
        
        This is a convenience method that builds the appropriate
        metadata query internally.
        """
        pass
    
    # ========== NEW: Relationship Queries ==========
    
    async def find_related_messages(self,
                                   message_id: int,
                                   relationship_types: List[str],
                                   max_distance: int = 2) -> List[Message]:
        """
        Find messages related to a given message.
        
        Args:
            message_id: Source message
            relationship_types: Types to follow
                ["semantic_similarity", "same_sender", 
                 "same_channel", "temporal_proximity",
                 "shared_breadcrumbs"]
            max_distance: How many hops to follow
        """
        pass
    
    # ========== NEW: Bulk Operations ==========
    
    async def update_metadata_bulk(self,
                                  message_ids: List[int],
                                  metadata_updates: Dict) -> int:
        """
        Update metadata for multiple messages.
        
        Args:
            message_ids: Messages to update
            metadata_updates: Fields to update/add
        
        Returns:
            Number of messages updated
        """
        pass
    
    async def update_confidence_bulk(self,
                                    updates: List[Tuple[int, float]]) -> int:
        """
        Update confidence scores in bulk.
        
        Args:
            updates: List of (message_id, new_confidence)
        
        Returns:
            Number of messages updated
        """
        pass
    
    # ========== Statistics & Monitoring ==========
    
    async def get_statistics(self,
                            time_window: Optional[str] = None) -> Dict:
        """
        Get infrastructure statistics.
        
        Returns:
            {
                "total_messages": int,
                "total_channels": int,
                "avg_confidence": float,
                "messages_with_embeddings": int,
                "storage_size_mb": float,
                "index_size_mb": float,
                "time_window_stats": {...}
            }
        """
        pass
    
    async def get_performance_metrics(self) -> Dict:
        """
        Get performance metrics.
        
        Returns:
            {
                "avg_search_latency_ms": float,
                "avg_store_latency_ms": float,
                "cache_hit_rate": float,
                "embedding_generation_ms": float
            }
        """
        pass
```

### 3. Data Models

```python
# claude_slack/models.py

from dataclasses import dataclass
from typing import Dict, Optional, Any, List
from datetime import datetime

@dataclass
class Message:
    """Message model for API responses."""
    id: int
    channel_id: str
    sender_id: str
    content: str
    timestamp: datetime
    confidence: Optional[float] = None
    metadata: Optional[Dict[str, Any]] = None
    
    @property
    def breadcrumbs(self) -> Dict:
        """Convenience accessor for breadcrumbs."""
        return self.metadata.get("breadcrumbs", {}) if self.metadata else {}

@dataclass
class SearchResult:
    """Search result with scoring information."""
    message: Message
    scores: Dict[str, float]  # similarity, confidence, decay, final
    
@dataclass  
class AggregationResult:
    """Aggregation result."""
    group_value: Any
    metrics: Dict[str, Any]
```

### 4. Metadata Filter Implementation

```python
# claude_slack/filters.py

import json
from typing import Dict, Any, List
from datetime import datetime, timedelta

class MetadataFilter:
    """
    Parse and apply MongoDB-like filters to metadata.
    """
    
    OPERATORS = {
        "$eq", "$ne", "$gt", "$gte", "$lt", "$lte",
        "$in", "$nin", "$contains", "$not_contains",
        "$exists", "$regex", "$and", "$or"
    }
    
    @classmethod
    def parse(cls, filters: Dict) -> str:
        """Convert filter dict to SQL WHERE clause."""
        conditions = []
        
        for field, constraint in filters.items():
            if field.startswith("$"):
                # Logical operator
                conditions.append(cls._parse_logical(field, constraint))
            else:
                # Field constraint
                conditions.append(cls._parse_field(field, constraint))
        
        return " AND ".join(conditions)
    
    @classmethod
    def _parse_field(cls, field: str, constraint: Any) -> str:
        """Parse a single field constraint."""
        # Handle nested fields (e.g., "breadcrumbs.files")
        json_path = cls._field_to_json_path(field)
        
        if isinstance(constraint, dict):
            # Operator-based constraint
            operator = list(constraint.keys())[0]
            value = constraint[operator]
            
            if operator == "$contains":
                # JSON contains check
                return f"json_extract(metadata, '{json_path}') LIKE '%{value}%'"
            elif operator == "$in":
                # IN clause
                values = ", ".join(f"'{v}'" for v in value)
                return f"json_extract(metadata, '{json_path}') IN ({values})"
            # ... handle other operators
        else:
            # Direct equality
            return f"json_extract(metadata, '{json_path}') = '{constraint}'"
    
    @classmethod
    def _field_to_json_path(cls, field: str) -> str:
        """Convert dot notation to JSON path."""
        # "breadcrumbs.files" -> "$.breadcrumbs.files"
        return "$." + field
```

### 5. Integration with Existing HybridStore

```python
# Modify existing hybrid_store.py to support new features

class HybridStore:
    # ... existing code ...
    
    async def query_by_metadata_sql(self, 
                                   sql_where: str,
                                   limit: int = 100) -> List[Dict]:
        """
        Execute metadata query using SQL WHERE clause.
        Used by the API layer for metadata filtering.
        """
        sql = f"""
            SELECT * FROM messages
            WHERE {sql_where}
            ORDER BY timestamp DESC
            LIMIT ?
        """
        cursor = self.conn.execute(sql, (limit,))
        return [dict(row) for row in cursor.fetchall()]
    
    async def aggregate_sql(self,
                           group_field: str,
                           metrics: List[str],
                           where_clause: str = "1=1") -> List[Dict]:
        """
        Execute aggregation query.
        Used by the API layer for pattern analysis.
        """
        # Build SQL aggregation query
        pass
```

### 6. Package Setup

```python
# setup.py

from setuptools import setup, find_packages

setup(
    name="claude-slack",
    version="4.1.0",
    packages=find_packages(),
    install_requires=[
        "aiosqlite>=0.19.0",
        "chromadb>=0.4.22",
        "numpy>=1.24.0",
    ],
    extras_require={
        "mcp": ["mcp>=0.1.0"],
    },
    python_requires=">=3.8",
    author="Your Name",
    description="Infrastructure layer for AI agent knowledge management",
    long_description=open("README.md").read(),
    long_description_content_type="text/markdown",
    url="https://github.com/yourusername/claude-slack",
)
```

## Implementation Priority

### Phase 1: Core API Structure (Week 1)
- [ ] Create `claude_slack` package structure
- [ ] Implement `ClaudeSlackAPI` class shell
- [ ] Define data models
- [ ] Setup package installation

### Phase 2: Metadata Queries (Week 1-2)
- [ ] Implement metadata filter parser
- [ ] Add `query_by_metadata` method
- [ ] Add `find_by_breadcrumbs` convenience method
- [ ] Test with complex queries

### Phase 3: Custom Ranking (Week 2)
- [ ] Implement `search_with_custom_ranker`
- [ ] Allow ranker injection
- [ ] Maintain performance with caching

### Phase 4: Aggregation (Week 2-3)
- [ ] Implement `aggregate_by_metadata`
- [ ] Add time window support
- [ ] Optimize for common patterns

### Phase 5: Testing & Documentation (Week 3)
- [ ] Unit tests for all API methods
- [ ] Integration tests with claude-brain
- [ ] API documentation
- [ ] Usage examples

## Success Criteria

1. **Clean Interface**: External systems only import from `claude_slack` package
2. **No Breaking Changes**: All existing MCP tools continue working
3. **Performance**: Metadata queries < 50ms for 10k messages
4. **Extensibility**: Custom rankers work without modifying claude-slack
5. **Documentation**: Complete API docs with examples

## Migration Path

1. **v4.0 → v4.1**: Add API without changing existing code
2. **MCP Tools**: Continue using existing HybridStore internally
3. **Python API**: New parallel interface for claude-brain
4. **Gradual Adoption**: claude-brain can start using API immediately

## Example Usage from Claude-Brain

```python
from claude_slack import ClaudeSlackAPI

# Initialize API
api = ClaudeSlackAPI(
    db_path="~/.claude/claude-slack/data/claude-slack.db"
)

# Query by breadcrumbs
auth_messages = await api.query_by_metadata({
    "breadcrumbs.decisions": {"$contains": "authentication"},
    "confidence": {"$gte": 0.8},
    "outcome": "success"
})

# Custom ranking
def expertise_ranker(message, scores):
    """Boost messages from recognized experts."""
    experts = ["security-expert", "auth-specialist"]
    if message.sender_id in experts:
        return scores["similarity"] * 1.5
    return scores["similarity"]

expert_solutions = await api.search_with_custom_ranker(
    query="JWT implementation",
    ranker=expertise_ranker
)

# Aggregate patterns
patterns = await api.aggregate_by_metadata(
    group_by="metadata.breadcrumbs.patterns",
    metrics=["count", "avg_confidence"],
    time_window="7d"
)
```

## Conclusion

This implementation plan provides claude-slack with the programmatic API needed to serve as the infrastructure layer for the intelligence system. By exposing metadata queries and custom ranking capabilities while maintaining its unopinionated nature, claude-slack becomes the solid foundation upon which claude-brain can build sophisticated intelligence features.